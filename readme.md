*** AI/ GPT Summarized Summary of my Raw Developer Notes ***

â¸»

ğŸ•¹ï¸ Othello AI (Minimax with Heuristics)

A fully playable Othello/Reversi game built in Python, featuring:
	â€¢	Human vs Human
	â€¢	Human vs AI
	â€¢	AI vs AI
	â€¢	Weighted heuristic evaluation
	â€¢	Optional alpha-beta pruning for faster search
	â€¢	Debug logging to debug.txt

â¸»

ğŸš€ How to Run (RUN FROM TOP LEVEL  "OTHELLO/")

# Run with explicit Python path
python3 -m othello.main

# or if your Python path is set:
python -m othello.main

ğŸ’¡ Run from the project root directory (where the othello/ folder resides).

â¸»

ğŸ® Game Modes

Mode	Description
1	Human vs Human
2	Human (Black) vs AI (White)
3	AI vs AI (auto-plays with pauses)


â¸»

âš™ï¸ Project Structure

othello/
â”œâ”€â”€ main.py              # Game entrypoint and loop logic  
â”œâ”€â”€ internal/  
â”‚   â”œâ”€â”€ board.py         # Board representation, rules, and move logic  
â”‚   â”œâ”€â”€ minimax.py       # Minimax + alpha-beta pruning AI  
â”‚   â”œâ”€â”€ heuristics.py    # Evaluation heuristics (disk diff, mobility, corners, etc.)  
â”‚   â”œâ”€â”€ cli.py           # Input/output, board rendering  
â”‚   â”œâ”€â”€ log.py           # Debug logger to file and stdout  
â”‚   â””â”€â”€ utils.py         # Helper functions (coord conversions, bounds, etc.)  
â””â”€â”€ debug.txt            # Created automatically when debug mode is active  



â¸»

ğŸ§  Heuristics Implemented

Each heuristic contributes to the AIâ€™s evaluation function:

Heuristic	Description
Disk Difference	Counts the difference between your pieces and your opponentâ€™s
Mobility	Measures how many legal moves each player has
Corner Control	Rewards owning corners, which canâ€™t be flipped
X-Square Penalty	Penalizes owning diagonally adjacent squares to unclaimed corners
(Planned) Stable Disks	Will estimate permanently safe disks later in development


â¸»

âš¡ Alpha-Beta Pruning

Alpha-Beta pruning is an optimization built on top of Minimax.
It skips exploring branches that cannot possibly influence the final decision â€” effectively reducing the number of evaluated nodes without changing the result.

How it works (simplified):
	â€¢	alpha = the best value the maximizing player can guarantee so far
	â€¢	beta  = the best value the minimizing player can guarantee so far
	â€¢	If at any point beta <= alpha, the algorithm stops exploring that branch (â€œcutoffâ€), since it wonâ€™t affect the final decision.

This pruning drastically speeds up deeper searches, especially when good move ordering is used (e.g., corners first).

â¸»

ğŸ”§ Enabling / Disabling Alpha-Beta Pruning

You can control pruning from the Minimax constructor inside main.py:

# With pruning (default and recommended)
minimax = Minimax(depth=4, alpha_beta=True, debug=True)

# Without pruning (explores all nodes, slower but exhaustive)
minimax = Minimax(depth=4, alpha_beta=False, debug=True)

ğŸ’¡ When debug=True, pruning events will appear in debug.txt (e.g. [debug] root alpha-beta cutoff).

â¸»

ğŸªµ Debug Logging

When debug mode is enabled:
	â€¢	All dprint() output is mirrored to debug.txt
	â€¢	The log file is created automatically next to main.py
	â€¢	It includes move selections, heuristic evaluations, and game results

â¸»

ğŸ§© Notes
	â€¢	Default AI depth is 4, adjustable in the Minimax constructor.
	â€¢	The terminal view clears between turns but logs remain fully preserved.
	â€¢	Requires Python â‰¥ 3.8.

